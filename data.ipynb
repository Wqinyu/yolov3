{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_file(url, destination):\n",
    "    response = requests.get(url, stream=True)\n",
    "    total_size_in_bytes = int(response.headers.get('content-length', 0))\n",
    "    block_size = 1024 # 1 Kibibyte\n",
    "    progress_bar = tqdm(total=total_size_in_bytes, unit='iB', unit_scale=True)\n",
    "    \n",
    "    with open(destination, 'wb') as file:\n",
    "        for data in response.iter_content(block_size):\n",
    "            progress_bar.update(len(data))\n",
    "            file.write(data)\n",
    "    progress_bar.close()\n",
    "    \n",
    "    if total_size_in_bytes != 0 and progress_bar.n != total_size_in_bytes:\n",
    "        print(\"ERROR, something went wrong\")\n",
    "    else:\n",
    "        print(f\"Download completed. File saved as {destination}\")\n",
    "\n",
    "# # VOC 2007 训练/验证数据\n",
    "# download_file(\n",
    "#     \"http://pjreddie.com/media/files/VOCtest_06-Nov-2007.tar\",\n",
    "#     \"VOCtrainval_06-Nov-2007.tar\"\n",
    "# )\n",
    "\n",
    "# # VOC 2007 测试数据\n",
    "# download_file(\n",
    "#     \"http://pjreddie.com/media/files/VOCtest_06-Nov-2007.tar\",\n",
    "#     \"VOCtest_06-Nov-2007.tar\"\n",
    "# )\n",
    "\n",
    "#VOC 2012 训练数据\n",
    "download_file(\n",
    "    \"http://pjreddie.com/media/files/VOCtrainval_11-May-2012.tar\",\n",
    "    \"VOCtrainval_11-May-2012.tar\"\n",
    ")\n",
    "download_file(\n",
    "    \"http://pjreddie.com/media/files/VOC2012test.tar\",\n",
    "    \"VOC2012test.tar\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "\n",
    "# 配置路径\n",
    "path_2007 = r'D:\\复旦\\研究生\\研一下\\神经网络与深度学习\\Homework2\\VOCtrainval_06-Nov-2007\\VOCdevkit\\VOC2007'\n",
    "path = r'D:\\复旦\\研究生\\研一下\\神经网络与深度学习\\Homework2\\VOCtrainval_11-May-2012\\VOCdevkit\\VOC2012'\n",
    "source_image_dir = path + r'\\JPEGImages'  # 原始图片存储路径\n",
    "source_xml_dir = path + r'\\Annotations'  # 原始XML存储路径\n",
    "train_image_dir = path + r'\\train\\images'  # 训练集图片存储路径\n",
    "train_xml_dir = path + r'\\train\\gt'  # 训练集XML存储路径\n",
    "val_image_dir = path + r'\\val\\images' # 验证集图片存储路径\n",
    "val_xml_dir = path + r'\\val\\gt'  # 验证集XML存储路径\n",
    "val_ratio = 0.2  # 验证集比例\n",
    "\n",
    "# 获取图片和XML文件\n",
    "image_files = {f.split('.')[0] for f in os.listdir(source_image_dir) if f.endswith('.jpg')}\n",
    "xml_files = {f.split('.')[0] for f in os.listdir(source_xml_dir) if f.endswith('.xml')}\n",
    "\n",
    "# 确保图片和XML文件名匹配\n",
    "matched_files = image_files.intersection(xml_files)\n",
    "matched_files = list(matched_files)  # 转换为列表以进行索引操作\n",
    "\n",
    "# 随机划分训练集和验证集\n",
    "np.random.seed(42)\n",
    "np.random.shuffle(matched_files)\n",
    "split_point = int(len(matched_files) * (1 - val_ratio))\n",
    "train_files = matched_files[:split_point]\n",
    "val_files = matched_files[split_point:]\n",
    "\n",
    "# 创建目录\n",
    "os.makedirs(train_image_dir, exist_ok=True)\n",
    "os.makedirs(train_xml_dir, exist_ok=True)\n",
    "os.makedirs(val_image_dir, exist_ok=True)\n",
    "os.makedirs(val_xml_dir, exist_ok=True)\n",
    "\n",
    "# 复制文件到新目录\n",
    "for filename in train_files:\n",
    "    shutil.copy(os.path.join(source_image_dir, filename + '.jpg'), os.path.join(train_image_dir, filename + '.jpg'))\n",
    "    shutil.copy(os.path.join(source_xml_dir, filename + '.xml'), os.path.join(train_xml_dir, filename + '.xml'))\n",
    "\n",
    "for filename in val_files:\n",
    "    shutil.copy(os.path.join(source_image_dir, filename + '.jpg'), os.path.join(val_image_dir, filename + '.jpg'))\n",
    "    shutil.copy(os.path.join(source_xml_dir, filename + '.xml'), os.path.join(val_xml_dir, filename + '.xml'))\n",
    "\n",
    "print(\"Files have been successfully copied to the training and validation directories.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "class VocToCoco:\n",
    "\n",
    "    def __init__(self, voc_gt_dir: str, output_coco_path: str) -> None:\n",
    "        self.voc_gt_dir = voc_gt_dir\n",
    "        self.output_coco_path = output_coco_path\n",
    "        self.categories_count = 1\n",
    "        self.images = []\n",
    "        self.categories = {}\n",
    "        self.annotations = []\n",
    "        self.data = defaultdict(list)\n",
    "\n",
    "    # 图片处理\n",
    "    def images_handle(self, root: ET.Element, img_id: int) -> None:\n",
    "        filename = root.find('filename').text.strip()\n",
    "        width = int(root.find('size').find('width').text)\n",
    "        height = int(root.find('size').find('height').text)\n",
    "\n",
    "        self.images.append({\n",
    "            'id': int(img_id),\n",
    "            'file_name': filename,\n",
    "            'height': height,\n",
    "            'width': width,\n",
    "        })\n",
    "\n",
    "    # 标签转换\n",
    "    def categories_handle(self, category: str) -> None:\n",
    "        if category not in self.categories:\n",
    "            self.categories[category] = {'id': len(self.categories) + 1, 'name': category}\n",
    "\n",
    "    # 标注转换\n",
    "    def annotations_handle(self, bbox: ET.Element, img_id: int, category: str) -> None:\n",
    "        x1 = int(float(bbox.find('xmin').text))\n",
    "        y1 = int(float(bbox.find('ymin').text))\n",
    "        x2 = int(float(bbox.find('xmax').text))\n",
    "        y2 = int(float(bbox.find('ymax').text))\n",
    "\n",
    "        width = x2 - x1\n",
    "        height = y2 - y1\n",
    "        area = width * height\n",
    "\n",
    "        self.annotations.append({\n",
    "            'id': self.categories_count,\n",
    "            'image_id': int(img_id),\n",
    "            'category_id': self.categories[category].get('id'),\n",
    "            'bbox': [x1, y1, width, height],\n",
    "            'area': area,\n",
    "            'iscrowd': 0\n",
    "        })\n",
    "        self.categories_count += 1\n",
    "\n",
    "    def parse_voc_annotation(self) -> None:\n",
    "        for img_id, filename in enumerate(os.listdir(self.voc_gt_dir), 1):\n",
    "            xml_file = os.path.join(self.voc_gt_dir, filename)\n",
    "            tree = ET.parse(xml_file)\n",
    "            root = tree.getroot()\n",
    "\n",
    "            self.images_handle(root, img_id)\n",
    "\n",
    "            for obj in root.iter('object'):\n",
    "                category = obj.find('name').text\n",
    "                self.categories_handle(category)\n",
    "\n",
    "                bbox = obj.find('bndbox')\n",
    "                self.annotations_handle(bbox, img_id, category)\n",
    "\n",
    "        self.data['images'] = self.images\n",
    "        self.data['categories'] = list(self.categories.values())\n",
    "        self.data['annotations'] = self.annotations\n",
    "\n",
    "        with open(self.output_coco_path, 'w') as f:\n",
    "            json.dump(self.data, f, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将训练集转化为coco格式\n",
    "voc_gt_dir = path + r'\\train\\gt'\n",
    "img_dir = path + r'\\train\\images'\n",
    "output_coco_path = path + r'\\train\\train.json'\n",
    "\n",
    "voc2coco = VocToCoco(voc_gt_dir, output_coco_path)\n",
    "voc2coco.parse_voc_annotation()\n",
    "\n",
    "\n",
    "# 将验证集转化为coco格式\n",
    "voc_gt_dir = path + r'\\val\\gt'\n",
    "img_dir = path + r'\\val\\images'\n",
    "output_coco_path = path + r'\\val\\val.json'\n",
    "\n",
    "voc2coco = VocToCoco(voc_gt_dir, output_coco_path)\n",
    "voc2coco.parse_voc_annotation()\n",
    "\n",
    "\n",
    "# 将测试集转化为coco格式\n",
    "voc_gt_dir = r'D:\\复旦\\研究生\\研一下\\神经网络与深度学习\\Homework2\\VOC2012test\\VOCdevkit\\VOC2012\\Annotations'\n",
    "img_dir = r'D:\\复旦\\研究生\\研一下\\神经网络与深度学习\\Homework2\\VOC2012test\\VOCdevkit\\VOC2012\\JPEGImages'\n",
    "output_coco_path = r'D:\\复旦\\研究生\\研一下\\神经网络与深度学习\\Homework2\\VOC2012test\\VOCdevkit\\VOC2012\\test.json'\n",
    "\n",
    "voc2coco = VocToCoco(voc_gt_dir, output_coco_path)\n",
    "voc2coco.parse_voc_annotation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 将验证集转化为coco格式\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m voc_gt_dir \u001b[38;5;241m=\u001b[39m \u001b[43mpath\u001b[49m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mgt\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      3\u001b[0m img_dir \u001b[38;5;241m=\u001b[39m path \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mimages\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      4\u001b[0m output_coco_path \u001b[38;5;241m=\u001b[39m path \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mval.json\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'path' is not defined"
     ]
    }
   ],
   "source": [
    "path = r'D:\\复旦\\研究生\\研一下\\神经网络与深度学习\\Homework2\\VOCtrainval_11-May-2012\\VOCdevkit\\VOC2012'\n",
    "# 将验证集转化为coco格式\n",
    "voc_gt_dir = path + r'\\val\\gt'\n",
    "img_dir = path + r'\\val\\images'\n",
    "output_coco_path = path + r'\\val\\val.json'\n",
    "\n",
    "voc2coco = VocToCoco(voc_gt_dir, output_coco_path)\n",
    "voc2coco.parse_voc_annotation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(45.70000076293945)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
